<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://zhang-xiaoru.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zhang-xiaoru.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-16T02:35:42+00:00</updated><id>https://zhang-xiaoru.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Negative Binomial Distribution</title><link href="https://zhang-xiaoru.github.io/blog/2025/negtive-binom/" rel="alternate" type="text/html" title="Negative Binomial Distribution"/><published>2025-07-13T22:00:00+00:00</published><updated>2025-07-13T22:00:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2025/negtive-binom</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2025/negtive-binom/"><![CDATA[<h1 id="negative-binomial-distribution">Negative Binomial Distribution</h1> <p>The negative binomial count the number of Bernoulli trials at which the $r$-th success occurs. If we denote random varaible $X$ as the number of trails required. Noticed that when event ${X=x}$ occurs, the $x$th trial should be success and there are exactly $r-1$ success in the $x-1$ trails. Therefor, the probability mass function (pmf) is</p> \[\begin{aligned} P(X=x|r,p)&amp;=\binom{x-1}{r-1}p^{r-1}(1-p)^{x-r}\cdot p\\ &amp;=\binom{x-1}{r-1}p^{r}(1-p)^{x-r},\quad x=r,r+1,\cdots \end{aligned}\] <p>The negative binomial is qeuivalently defined as the pmf of specfic failures before the $r$-th success. If $X$ is still the number of trails at which the $r$-th success occurs, the number of failures before is therefor $Y=X-r$. Thus, we find the pmf for $Y$ as</p> \[P(Y=y|r, p)=\binom{r+y-1}{y}p^r(1-p)^y,\quad y=0, 1, \cdots\] <h1 id="sum-of-probability-mass-function">Sum of Probability Mass Function</h1> <p>The pmf we found above should satisfy the condition $\sum_xP(X=x)=1$. Therefor</p> \[\sum_{x=r}^\infty\binom{x-1}{r-1}p^r(1-p)^{x-r}=\sum_{y=0}^\infty\binom{r+y-1}{y}p^r(1-p)^y=1\] <p>This sum is quit useful for some combinatorial problems, can the proof can be shown using the series expansion of $(1+x)^\alpha$. Noticed that</p> \[\begin{aligned} \binom{r+y-1}{y}=\frac{(r+y-1)(r+y-2)\cdots r}{y!}\\ =(-1)^k\frac{(-r)(-r-1)\cdots(-r-(y-1))}{y!} \end{aligned}\] <p>NOticed that this is the expansion coefficient of $(1-x)^{-r}$, which is</p> \[(1-x)^{-r}=1+(-r)(-x)+\frac{(-r)(-r-1)}{2!}(-x)^2\cdots\] <p>thus, the sumation is equivalent</p> \[p^r\sum_{y=0}^{\infty}\binom{r+y-1}{y}q^y=p^r\sum_{y=0}^\infty\frac{(-r)(-r-1)\cdots(-r-(y-1))}{y!}(-q)^y=p^r(1-q)^{-r}=1\]]]></content><author><name></name></author><category term="combinatorial"/><summary type="html"><![CDATA[a brife note for negtivae binomial distribution]]></summary></entry><entry><title type="html">Catalan Numbers</title><link href="https://zhang-xiaoru.github.io/blog/2025/catalan-num/" rel="alternate" type="text/html" title="Catalan Numbers"/><published>2025-07-07T17:12:00+00:00</published><updated>2025-07-07T17:12:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2025/catalan-num</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2025/catalan-num/"><![CDATA[<h1 id="catalan-numbers">Catalan Numbers</h1> <p>Catalan numbers occurs in various counting problems. The $n$-th Catalan number is expressed as \(C_n=\frac{1}{n+1}\binom{2n}{n}\)</p> <p>One frequently appeared problem would be <strong>Dyck words</strong>.</p> <h2 id="deck-words">Deck words</h2> <p>A Dyck word is a string consisting of same naumber of X and Y’s such that no initial segment of string has more Y than X. For example, a Dyck words XXYYXY has initial segment {X, XX, XXY, XXYY, XXYYX}. All of them has number of Y less than X.</p> <p>Catalan number counts the number of Dyck words with length $2n$.</p> <h2 id="random-walks">Random Walks</h2> <p>If we replace the X as 1 and Y as -1 in the Dyck word, it is equivalent to a random walks that the path reaches 0 at the end and <strong>does not pass the origin</strong>. The number of such paths can be found using reflection principles.</p> <p>Suppose the number of $+1$ and $-1$steps in the walks are both $n$. We consider the complementray case instead, i.e., the number of ways that the path pass the origin at some point. More specifically, if $(s, i)$ denote that the walk is at position $s$ at $i$-th steps, we are looking for a path satisfying $(0, 0)$ and $(2n, 0)$, and $\exist 0\leq j\leq 2n$ s.t. $b&lt;0$ for $(b, j)$. For such a path, we can always find a specific step $k$ s.t. the walk reach $(-1, k)$.</p> <p>The reflection principles essintally states that if we flip the path between $0$ and $k$ at the point $k$ respect to $-1$ axis, we get then get a new path that start at $(0, -2)$ and reach $(2n, 0)$. We can do this for every path we consider and get a unique path. Therefor, the question becomes finding number of paths that start $(0, -2)$ and reach $(2n, 0)$. Such path should contains $n-1$ steps of $-1$ and $n+1$ steps of $+1$. The number of permutations to form paths is thus $\frac{(2n)!}{(n-1)!(n+1)!}$. Thus the number of path from $(0, 0)$ to $(2n, 0)$ without passing the origin is \(\frac{(2n)!}{n!n!}-\frac{(2n)!}{(n-1)!(n+1)!}=\binom{2n}{n}-\frac{n}{n+1}\binom{2n}{n}=\frac{1}{n+1}\binom{2n}{n}=C_n\)</p> <blockquote> <h3 id="reflection-principle">Reflection Principle</h3> <p>Suppose we have a random walk $\left{S_i\right}$ with path that $S_0=a$ and $S_n=b$. Denote $N_n(a, b)$ <strong>the number of all possible paths</strong> from $(0, a)$ to $(n, b)$ and $N_n^0(a, b)$ <strong>the number of those paths that visit the origin</strong>, i.e. the path contain point $(k, 0)$.</p> <p>The reflection principle simply states that <strong>the number of paths that visit the origin is the same with the number of ‘reflected’ paths at the first visit of the origin.</strong> \(N_n^0(a, b)=N_n(-a, b), \quad a, b&gt;0\) The essential idea behind the relfection principle is that by reflecting the path from $0$ to $k$, we create a mapping from the original path to the path from $(0, -a)$ to $(n, b)$. The mapping is bijection by noticing that every inverse will maped to a path that pass the origin.</p> </blockquote>]]></content><author><name></name></author><category term="math"/><category term="combinatorial"/><category term="random walks"/><summary type="html"><![CDATA[counting for binary string with non-exceeding segments]]></summary></entry><entry><title type="html">LaTex To Word Conversion</title><link href="https://zhang-xiaoru.github.io/blog/2025/latex-2-word/" rel="alternate" type="text/html" title="LaTex To Word Conversion"/><published>2025-07-01T17:00:00+00:00</published><updated>2025-07-01T17:00:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2025/latex-2-word</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2025/latex-2-word/"><![CDATA[<h1 id="latex-to-word-conversion">Latex to Word conversion</h1> <p>I have been using Latex for writting and has very limitted knowledge on using word. However, there is time when the literature have to be in the Word format, and it is extremely inconveninent especially for scientific writing. To avoid learning how to write in Word, I start to search how to convert Latex into Word.</p> <p><a href="https://pandoc.org/index.html">Pandoc</a> so far has been a very useful tool fulliing that purpose. To start, first need to install it. The installtion is well documented in Pandoc home page. For MAC user as myself, it can be installed using Homebrew using simply comand</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>pandoc
</code></pre></div></div> <p>A simple conversion can be done with the command</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>panddoc your_tex_file_name.tex -o your_docx_file_name.docx
</code></pre></div></div> <p>A simple conversion like this may not be satisfactoy, especially if you need to give this to your supervisor. Few problems still need to be adress</p> <ol> <li>Formatting of the converted file (font size, font style etc)</li> <li>Proper citations</li> <li>Numbering and correct referencing of figures, equations tabels etc.</li> </ol> <h2 id="conversion-file-formatting">Conversion file formatting</h2> <p>The command above convert the tex file to docx in defalt format. To specify the format of the docx, you can create a docx in which you have customized your format and use it as a reference during pandoc conversion</p> <p>Frist create a reference docx file for you to customize format, using the command</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc -o custom_reference_file.docx --print-default-data-file reference.docx
</code></pre></div></div> <p>This should create a word file named <code class="language-plaintext highlighter-rouge">custom_reference_file.docx</code> with content as follows</p> <p><strong>Here should be a demo figure</strong></p> <p>Then you can change the format in this docx file accordingly (change the style of the docx), and use it as the template for pandas conversion</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc your_tex_file_name.tex --reference-doc=custom_reference_file.docx -o your_docx_file_name.docx
</code></pre></div></div> <p>The converted file know should has the same style as you set up in the reference docx.</p> <h2 id="citations">Citations</h2> <p>You can provide the Biblatex file you used for LaTex to pandoc for bibliography using <code class="language-plaintext highlighter-rouge">--bibliography</code>. You should provide the relative path of your <code class="language-plaintext highlighter-rouge">.bib</code> file just as you would do in latex. An example would be</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc your_tex_file_name.tex <span class="nt">--bibliography</span><span class="o">=</span>your_references.bib <span class="nt">-o</span> your_docx_file_name.docx
</code></pre></div></div> <p>However, the citation in the coverted docx file might not shown up correctly. This is usually resolved using pandoc-citeproc by specifying command</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc your_tex_file_name.tex <span class="nt">--citeproc</span> <span class="nt">--bibliography</span><span class="o">=</span>your_reference.bib <span class="nt">-o</span> your_docx_file_name.docx
</code></pre></div></div> <p>If you have specific citation style preference, you can also specify that in pandoc through citation-style-language file <code class="language-plaintext highlighter-rouge">.csl</code>. Usually this will be provided by the publisher of the specific journal you are targeting. You can also find the file from theis Github repo <a href="https://github.com/citation-style-language/styles">https://github.com/citation-style-language/styles</a>. After you have the <code class="language-plaintext highlighter-rouge">.csl</code> file, specify that in the pandoc command</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc your_tex_file_name.tex <span class="nt">--citeproc</span> <span class="nt">--bibliography</span><span class="o">=</span>your_reference.bib <span class="nt">--csl</span><span class="o">=</span>your_csl.csl <span class="nt">-o</span> your docx_file_name.docx
</code></pre></div></div> <h2 id="cross-reference">Cross reference</h2> <p>Pandoc do a pretty good job converting the LaTex equations to word question with no requirement of equition editors like MathType, which is a major reason why I chose convert LaTex to Word in pandoc instead of just writting in docx.</p> <ul> <li>Noticed that some math commands in LaTex, especially some provided by packages like amsmath are not supported in pandoc conversion. Pandoc will still make the conervsion by simply phrase unknown commands in its original form (for example, <code class="language-plaintext highlighter-rouge">\text</code> in <code class="language-plaintext highlighter-rouge">align</code> enivronment is not recognized by pandoc, so whenever <code class="language-plaintext highlighter-rouge">\text{}</code> appears in LaTex, the pandoc will simply convert that into ‘\text{what you wrote}’ in the docx file )</li> <li>This problem could be reolvsed by making a pandoc filter so that the unrecognized commands is detecated and converted to someting in replace.</li> </ul> <p>However, in LaTex, the equations, labels, tabels or sections can be numbered. While native pandoc dosen’t support this feature of numbering. Also, in LaTex, referencing these object is easily done by creating <code class="language-plaintext highlighter-rouge">\label{}</code> for the one that you wish to refer and use <code class="language-plaintext highlighter-rouge">\ref{label_name}</code> at where you wish to refer in you article. They will be ference as the correponsidng number.</p> <p><strong>Example figures</strong></p> <p>However, this is not supported natively in pandoc, which is quit problematic espeically for scintific writting. The feature can be achived through pandoc filters. There are many online resoruces providing filters for different features, and I have found pandoc-crossref and pandoc-tex-numbering quit useful for cross-referencing in my situation.</p> <p><strong>pandoc-crossref</strong>: this extension is one popular cross referencing extension for pandoc. It enables lot of different features and customization options. However, it does not officially support LaTex. Some has shown that it still work on LaTex with restrictions, but in my case it doesn’t works well. I haven’t find a way to fixed the issue.</p> <ul> <li>works for simply eqution numbering though</li> </ul> <p><strong>pandoc-tex-numbering</strong>: this filter does not support as many features as pandoc and is also not as well documented as pandoc-crossref, but it did a pretty decent job numbering and cross-referenceing the object in LaTex to Word.</p> <ul> <li>It also support multiline equations and subfigures, quit handy</li> </ul> <h3 id="equations">Equations</h3> <p>For equation numbering, you can use pandoc-crossref specifying</p> <ul> <li><code class="language-plaintext highlighter-rouge">autoEqnLabels</code>: automatically number all display equations</li> <li><code class="language-plaintext highlighter-rouge">tableEqns</code>: word doesn’t natively support equation numbering. If this is not specified as <code class="language-plaintext highlighter-rouge">true</code>, the number will be add directly into the equation block. If <code class="language-plaintext highlighter-rouge">true</code>, a table will created so that number can be put at the end of line.</li> </ul> <p>To do this, specify</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc your_tex_file_name.tex <span class="nt">--filter</span> pandoc-crossref <span class="nt">-M</span> autoEqnLabels <span class="nt">-o</span> your_docx_file_name.docx
</code></pre></div></div> <p>this will generate numbering for the equations. Or</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc your_tex_file_name.tex <span class="nt">--filter</span> pandoc-crossref <span class="nt">-M</span> autoEqnLabels <span class="nt">-M</span> tableEqns <span class="nt">-o</span> your_docx_file_name.docx
</code></pre></div></div> <p>and the number will be put at the end of line.</p> <p>The reference of the equations is not right though.</p> <p>Pandoc-tex-numbering handle this equit will. You can use it as the filter for pandoc</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc your_tex_file_name.tex <span class="nt">--filter</span> pandoc-tex-numbering <span class="nt">-o</span> your_docx_file_name.docx
</code></pre></div></div> <p>The defult setting will numbering each of your sections in levels, and numbering the number and figures accordingly (like 1.1.2 for equation 2 in section 1.1). I don’t want section numbering, and leveled numbering I can specify that by passing the metadata as</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc your_tex_file_name.tex <span class="nt">--filter</span> pandoc-tex-numbering <span class="nt">-M</span> number-sections<span class="o">=</span><span class="nb">false</span> <span class="nt">-M</span> number-reset-level<span class="o">=</span>0 <span class="nt">-o</span> your_docx_file_name.docx
</code></pre></div></div> <p>More metadata command can be found in their Github repo. The number though is in the math block and it didn’t seems to be a way to put it at the end of the line.</p> <h3 id="figures-and-tabels">Figures and Tabels</h3> <p>In LaTex, the numbering of figures or tables will be shown as ‘Figure #: you caption’ in the caption region of the figure. Pandoc-tex-numbering can also do this during the conversing. You can customize the prefix using <code class="language-plaintext highlighter-rouge">figure-prefix</code>. The default value is “Figure”</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandoc your_tex_file_name.tex --filter pandoc_tex_numbering -M figure-prefix="Fig" -o your_docx_file_name.docx
</code></pre></div></div> <p>This will specify the prefix of figure as “Fig #: your caption”.</p> <h2 id="summary">Summary</h2> <p>Now, the generated Word file will have pre-specified format, correct citations, corss-reference and numbering for equastions and figures. It will match the standard to give to your PI perhaps with few minor adjustments.</p> <h2 id="ref">Ref</h2> <ul> <li>https://tex.stackexchange.com/questions/369424/pandoc-latex-to-docx-change-font-size</li> <li>https://github.com/fncokg/pandoc-tex-numbering</li> <li>https://ja01.chem.buffalo.edu/etcetera/latex-pandoc-word.html</li> <li>https://const-ae.name/post/2024-08-02-latex-to-word-conversion-with-pandoc/</li> <li>https://medium.com/@zhelinchen91/how-to-convert-from-latex-to-ms-word-with-pandoc-f2045a762293</li> </ul>]]></content><author><name></name></author><category term="tech"/><category term="LaTex"/><summary type="html"><![CDATA[convert LaTex file into Word with formatting]]></summary></entry><entry><title type="html">Guide to TACC</title><link href="https://zhang-xiaoru.github.io/blog/2025/tacc-lonestar6/" rel="alternate" type="text/html" title="Guide to TACC"/><published>2025-01-26T22:16:00+00:00</published><updated>2025-01-26T22:16:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2025/tacc-lonestar6</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2025/tacc-lonestar6/"><![CDATA[<h2 id="file-systems-and-managing-file-on-tacc">File systems and managing file on TACC</h2> <p>Lonestart6’s startup mechanimsms defines corresponding account-level enviornment variable <code class="language-plaintext highlighter-rouge">$HOME</code>, <code class="language-plaintext highlighter-rouge">$SCRATCH</code> and <code class="language-plaintext highlighter-rouge">$WORK</code> , each store the paths to the chorresponding directories you own on each file system</p>]]></content><author><name></name></author><category term="tech"/><category term="HPC"/><category term="Linux"/><summary type="html"><![CDATA[a note for using Texas Advanced Computing Center (TACC)]]></summary></entry><entry><title type="html">Enable Markdown Callout in Hugo</title><link href="https://zhang-xiaoru.github.io/blog/2025/callout/" rel="alternate" type="text/html" title="Enable Markdown Callout in Hugo"/><published>2025-01-15T07:30:00+00:00</published><updated>2025-01-15T07:30:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2025/callout</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2025/callout/"><![CDATA[<p>Callouts or admonitions are blockquotes that empohasize information. The basic Markdown syntax for are</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gt">&gt;[!NOTE]</span>
<span class="gt">&gt;your input here</span>
<span class="gt">
&gt;[!TIP]</span>
<span class="gt">&gt;your input here</span>
<span class="gt">
&gt;[!IMPORTANT]</span>
<span class="gt">&gt;your input here</span>
<span class="gt">
&gt;[!WARNING]</span>
<span class="gt">&gt;your inpu here</span>
<span class="gt">
&gt;[!CAUTION]</span>
<span class="gt">&gt;your input here</span>
</code></pre></div></div> <p>Howere, PaperMod theme doesn’t seems to support callout. Following the documents from Hugo, this can be achived using blockquote render hook.</p> <p>In <code class="language-plaintext highlighter-rouge">layouts/_defualt/_markup/</code> create an HTML with following code</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code>


  <span class="nt">&lt;blockquote</span> <span class="na">class=</span><span class="s">"alert alert-"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;p</span> <span class="na">class=</span><span class="s">"alert-heading"</span><span class="nt">&gt;</span>
      
      
        
      
        
      
    <span class="nt">&lt;/p&gt;</span>
    
  <span class="nt">&lt;/blockquote&gt;</span>

  <span class="nt">&lt;blockquote&gt;</span>
    
  <span class="nt">&lt;/blockquote&gt;</span>

</code></pre></div></div> <p>this blockquote render hook renders the callout if a callout designator is present. Then add entrices for callout box label in <code class="language-plaintext highlighter-rouge">i18n/i18n/en.yaml</code></p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">caution</span>
  <span class="na">translation</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Caution"</span>

<span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">important</span>
  <span class="na">translation</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Important"</span>

<span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">note</span>
  <span class="na">translation</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Note"</span>

<span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">tip</span>
  <span class="na">translation</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Tip"</span>

<span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">warning</span>
  <span class="na">translation</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Warning"</span>
</code></pre></div></div> <p>The rendered callout looks like this</p> <blockquote> <p>[!IMPORTANT]</p> <p>This is how the callout looks like.</p> </blockquote>]]></content><author><name></name></author><category term="tech"/><category term="blog-making"/><category term="Hugo"/><summary type="html"><![CDATA[Add markdown callout in Hugo blog]]></summary></entry><entry><title type="html">Python Type Annotations</title><link href="https://zhang-xiaoru.github.io/blog/2025/type-anno/" rel="alternate" type="text/html" title="Python Type Annotations"/><published>2025-01-13T22:27:00+00:00</published><updated>2025-01-13T22:27:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2025/type-anno</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2025/type-anno/"><![CDATA[<p>In Python, a type annotation or type hint is an optional notation that allows users specifies the type of parameters and return of a function.</p> <p>Examples:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
  <span class="sh">'''</span><span class="s">Specify argument and return as int</span><span class="sh">'''</span>
  <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

<span class="k">def</span> <span class="nf">add_list</span><span class="p">(</span><span class="n">nums</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
  <span class="sh">'''</span><span class="s">Specify argument as list of int and retun as int</span><span class="sh">'''</span>
  <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">nums</span><span class="p">:</span>
    <span class="nb">sum</span> <span class="o">+=</span> <span class="n">num</span>
   <span class="n">retun</span> <span class="nb">sum</span>

<span class="k">def</span> <span class="nf">make_dict</span><span class="p">(</span><span class="n">keys</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">values</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
  <span class="sh">'''</span><span class="s">Specift argument as list of int and str,
  the return as a dict whose kets should all be str and value be int</span><span class="sh">'''</span>
  <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="nb">dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
  <span class="k">return</span> <span class="nb">dict</span>
</code></pre></div></div> <p>Notice that adding type annotations to a function definitions <strong>does not require the Python interpreter to check type arguments or return a converted value</strong>. The function will work as well with other type of input. The type annotations works more of a function documentation, which helps increasing the readablity of the code.</p> <p>Sometimes an argument is expected to work for different types, this can be done using <code class="language-plaintext highlighter-rouge">Union</code> class from the <code class="language-plaintext highlighter-rouge">typing</code> module</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Union</span>

<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">b</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
  <span class="sh">'''</span><span class="s">Specify argument and return as int or float</span><span class="sh">'''</span>
  <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

</code></pre></div></div> <p>For Python 3.10 and later, this can be achived symply by <code class="language-plaintext highlighter-rouge">|</code> operator</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">:</span>
  <span class="sh">'''</span><span class="s">Specify argument and return as int or float</span><span class="sh">'''</span>
  <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
  
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">typing</code> includes various generic types and ability to customize type, which would be useful for complicated type relationships. Check a few <a href="https://docs.python.org/3/library/typing.html#module-typing">examples</a> .</p> <p>A cheat sheet of various common types in Python can be found <a href="https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html">here</a>.</p> <blockquote> <p>[!NOTE] Third party tools such as <a href="https://mypy-lang.org/">mypy</a> can analyze code containing type annotations and flag potential problems.</p> </blockquote> <p><strong>Ref:</strong></p> <ul> <li><a href="https://runestone.academy/ns/books/published/fopp/Functions/TypeAnnotations.html">https://runestone.academy/ns/books/published/fopp/Functions/TypeAnnotations.html</a></li> </ul>]]></content><author><name></name></author><category term="tech"/><category term="Python"/><summary type="html"><![CDATA[making type hint for Python functions]]></summary></entry><entry><title type="html">Martingales</title><link href="https://zhang-xiaoru.github.io/blog/2024/martingales/" rel="alternate" type="text/html" title="Martingales"/><published>2024-12-17T19:20:00+00:00</published><updated>2024-12-17T19:20:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2024/martingales</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2024/martingales/"><![CDATA[<p>The conecpt of martingales arise from fair games in gambling. Suppose a gambler with initial capital $S_0$ repeatedly playing a game. Let ${S_n}$ be the sequence representing his caotial after each play. The gambler know the exact values of $S_0,S_1\cdots, S_n$ before $n+1$ game, but can only guess at the future games. If the game is fair, the gambler would expect no change in his present capital on average, no matter what past information he got. \(E(S_{n+1}|S_0, S_1, \cdots, S_n) = S_n\notag\) Random sequence satisified the above relation are called ‘martingales’.</p> <h1 id="martingales">Martingales</h1> <p>A sequence $S={S_n:n\geq 0}$ is called a <strong>martingale</strong> with respecto to the sequence $X={X_n:n\geq0}$ if for all $n\geq0$</p> <ul> <li> <table> <tbody> <tr> <td>$E</td> <td>S_n</td> <td>&lt;\infty$</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>$E(S_{n+1}</td> <td>X_0, X_1, \cdots, X_n)=S_n$</td> </tr> </tbody> </table> </li> </ul> <p>The conditional expecatation of $Y$ given $X$ denoted as $E(Y|X)$ is defined as \(E(Y|X)=\int_{-\infty}^\infty yf_{Y|X}(y|X)\mathrm{d}y\notag\) where $f_{Y|X}(y|x)=\frac{f(x, y)}{f_X(x)}$ is the conditional density function.</p> <p>The definition of martingale here is introduce sequence ${X_n}$ since in cases, the sequence it self may not be a martingale, while it is possible to find some function $\phi$ s.t. ${S_n=\phi(X_n):x\geq1}$ is a martingale.</p>]]></content><author><name></name></author><category term="probability"/><category term="statistics"/><category term="random process"/><summary type="html"><![CDATA[a short intro to martingales]]></summary></entry><entry><title type="html">Cross Validation For Time Series Data</title><link href="https://zhang-xiaoru.github.io/blog/2024/timeseries-cv/" rel="alternate" type="text/html" title="Cross Validation For Time Series Data"/><published>2024-11-24T21:04:00+00:00</published><updated>2024-11-24T21:04:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2024/timeseries-cv</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2024/timeseries-cv/"><![CDATA[<p>The usual case of cross-validation with random samples is not suitable for time series data since the shuffling process will include future data to forecast values in the past.</p> <p>One of the way to make corss validation set for time series data is to chose segments of series as different traning sets. he successive traning sets need to be supersets of those that come beofre. Then select the following piece of sereis of the traning set as the vlidation set.</p> <p>Example using <code class="language-plaintext highlighter-rouge">sklearn.model_selection.TimeSeriesSplit</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">Time</span> <span class="n">SeriesSplit</span>

<span class="c1"># Create series dataset
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>

<span class="c1"># Create 5 fold spliting
</span><span class="n">tscv</span> <span class="o">=</span> <span class="nc">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># print the split result
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">tscv</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Split </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Train indices: </span><span class="si">{</span><span class="n">train_index</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Test indices: </span><span class="si">{</span><span class="n">test_index</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">TimeSeriesSplit</code> takes serval parameters:</p> <ul> <li><code class="language-plaintext highlighter-rouge">n_split</code>: number of splits</li> <li><code class="language-plaintext highlighter-rouge">max_train_size</code>: maximum size of a single traning set, <code class="language-plaintext highlighter-rouge">default=None</code></li> <li><code class="language-plaintext highlighter-rouge">test_size</code>: size of the test set, <code class="language-plaintext highlighter-rouge">default=None</code>. If <code class="language-plaintext highlighter-rouge">default</code>, the isze of test set is <code class="language-plaintext highlighter-rouge">n_samples // (n_splits + 1)</code>, which is maximum test size with <code class="language-plaintext highlighter-rouge">gap=0</code></li> <li><code class="language-plaintext highlighter-rouge">gap</code>: Number of samples excluded after and before the train set and test set</li> </ul> <p><code class="language-plaintext highlighter-rouge">split</code> method returns a iterator for generated indices for each splited traning and test set</p> <ul> <li><code class="language-plaintext highlighter-rouge">X</code>: array-like of shape (n_samples, n_features), where n_sample is number of samples and n_features is the number of features.</li> <li><code class="language-plaintext highlighter-rouge">y</code>: <code class="language-plaintext highlighter-rouge">defualt=None</code></li> <li><code class="language-plaintext highlighter-rouge">group</code>: <code class="language-plaintext highlighter-rouge">defult=None</code></li> </ul>]]></content><author><name></name></author><category term="tech"/><category term="machine learning"/><category term="time series"/><summary type="html"><![CDATA[how to perform cross validation for time sequence data]]></summary></entry><entry><title type="html">Make shortcut for directory in zsh</title><link href="https://zhang-xiaoru.github.io/blog/2024/dir-shortcut/" rel="alternate" type="text/html" title="Make shortcut for directory in zsh"/><published>2024-11-11T16:29:00+00:00</published><updated>2024-11-11T16:29:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2024/dir-shortcut</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2024/dir-shortcut/"><![CDATA[<p>It is some time useful to create a short cut to the frequently used working directories so that I don’t have to type the path every time when I try to open it in the terminal</p> <h1 id="using-aliases">Using Aliases</h1> <p>To make an alias that persistent, one can add the alias to the zsh configuration file</p> <ol> <li> <p>Open configuration file <code class="language-plaintext highlighter-rouge">~/.zshrc</code></p> </li> <li> <p>Add create an alias that <code class="language-plaintext highlighter-rouge">cd</code> to the desired directory</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">alias </span>workdir <span class="o">=</span> <span class="s1">'cd /path to your directory'</span>
<span class="c"># workdir is the name for your short cut</span>
</code></pre></div> </div> </li> <li> <p>Save the file and reload the configuration file</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">source</span> ~/.zshrc
</code></pre></div> </div> </li> <li> <p>Simply type <code class="language-plaintext highlighter-rouge">workdir</code> in the terminal to move to the desired directory</p> </li> </ol> <h1 id="create-variable-for-the-path">Create variable for the path</h1> <p>This can also be done by create a varaible representing the path for the directory in shell configuration file.</p> <ol> <li> <p>Open zsh shell configuration file <code class="language-plaintext highlighter-rouge">~/.zshrc</code></p> </li> <li> <p>Create a vraible for the path of the directory you wish to create short path</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">workdir</span><span class="o">=</span><span class="s2">"/path to your directory"</span>
<span class="c"># workdir is the name for your short cut</span>
</code></pre></div> </div> </li> <li> <p>Save the file and reload the configuration file</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">source</span> ~/.zshrc
</code></pre></div> </div> </li> <li> <p>Use the varibale as follow</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> <span class="nv">$workdir</span>
</code></pre></div> </div> </li> </ol>]]></content><author><name></name></author><category term="tech"/><category term="Terminal"/><category term="Mac"/><summary type="html"><![CDATA[way to make shortcut to working directories]]></summary></entry><entry><title type="html">Decision Tree</title><link href="https://zhang-xiaoru.github.io/blog/2024/decision-tree/" rel="alternate" type="text/html" title="Decision Tree"/><published>2024-11-11T16:10:00+00:00</published><updated>2024-11-11T16:10:00+00:00</updated><id>https://zhang-xiaoru.github.io/blog/2024/decision-tree</id><content type="html" xml:base="https://zhang-xiaoru.github.io/blog/2024/decision-tree/"><![CDATA[<h1 id="regression-trees">Regression Trees</h1> <p>The regression trees use the condition on each node to split the predictor space into different region, representing by the leaves of the tree. The predicted mean of the response for a feacture point fall in the leave is given by the responbse average of traning observation within the region. In principle, the shape of the region can be airbutreary, but are typically troches as high-dimensional boxes.</p> <h2 id="formulasime">Formulasime</h2> <ul> <li> <p>Divide the $d$ dimensional predictor space repressenting by data vector $\mathbf{x}=(x_1, x_2, \cdots, x_d)$, into $J$ distinct non-ocerlaping regions $R_1, R_2, \cdots, R_J$.</p> </li> <li> <p>For every observation that falls into the region $R_j$, the prediction is same, which is the average of the response value for the traning objercation fall in $R_j$</p> </li> <li> <p>The goal is to find optimized regions ${R_i}$ that minimized the error \(\sum_{j=1}^{J}\sum_{\mathbf{x}_i\in R_j}(y_i-\hat{y}_{R_j}) \notag\) where $y_i$ is the reponse of train data point $\mathbf{x}<em>i$ amd $\hat{y}</em>{R_j}$ is the average of traning observation within $R_j$</p> </li> </ul> <h2 id="optimization">Optimization</h2> <p>Use recursive binary splitting, a top-down, greedy approach to find the minimized error.</p> <ol> <li> <table> <tbody> <tr> <td>For specific predictor $x_j$, splite the predictor space in to $R_1={\mathbf{x}</td> <td>x_j&lt;s_j}$ and $R_2={\mathbf{x}</td> <td>x_j\geq s_j}$, and find s that minimized the error.</td> </tr> </tbody> </table> </li> <li>Search thorugh all predictors and find the $(x_i, s_i)$ that has the smallest error.</li> <li>Repeat process 1, 2 for one of the splited region</li> <li>Repeat 3 until all region contains observations less than specific value</li> </ol> <h2 id="regularization">Regularization</h2> <p>If the tree we generate is too big, the tree would overfit the data. However, the naive approach simply stop the above process early will prohibite the tree to find a possible good split in deeper tree.</p> <p>A better strategy is to grow a very large tree and then prune it back in order to obtain a subtree.</p> <h3 id="cost-complexity-pruning-weakest-link-pruning">Cost complexity pruning (weakest link pruning)</h3> <p>Rather than consideirng every possible subtree, the cost complexity pruning use a hyperparameter $\alpha$ to add a punishment term for size of tree in the error function. For each value of $\alpha$ corresponds a subtree $T$ that minimized the error function \(\sum_{m=1}^{|T|}\sum_{\mathbf{x}_i\in{R_m}}(y_i-\hat{y}_{R_i})+\alpha|T|\notag\) where |T| represent the number of terminal nodes of the tree.</p> <h1 id="classification-trees">Classification Trees</h1> <p>The prdiction of an classification trees is same for each observation fall in the splited predictor space region, given by the most commonly occurring class of traning obsercations in the region.</p> <h1 id="ensemble-method-for-decistion-trees">Ensemble Method for Decistion Trees</h1> <p>An ensemble method is an approach that combines many simple weak learning to obtain a potentially very powerful model.</p> <h2 id="bagging">Bagging</h2> <p>The idea of bagging or Bootstrap aggregation is to take many traning sets from the population, and buid separte drecition modesl using for each traning set. The prediction is given by the avrageds of these model. By doing such, the variacne of the statistical learning model is reduced.</p> <p>In practice, instead of getting multiple traning set, people resample from the single training set, getting different bootstrapped traning data set. Suppose we enerate $B$ different traning sets from the original datastes, for each traning sets, we traning the model and get a regression relationship $\hat{f}_i(\mathbf{X})$, the final model would be the average of all the predictions \(f_{\text{beg}} = \frac{1}{B}\sum_{i=1}^{B}\hat{f}_i(\mathbf{X})\notag\)</p> <ul> <li>Bagging can be applied to many regression methods.</li> <li>Trees are growning using $B$ traning set, and are not pruned. Since the averaging process will reduces the variance.</li> </ul> <h2 id="random-forests">Random Forests</h2> <p>In random forest model, numbers of trees are duilded on bootstrapped traning smaples, and the overall prediction is given by the average. When building each decision trees, instead of splitting the predictor space searching through all predictors, a random sample of $m$ predictors is chosen.</p> <ul> <li>A fresh sample of $m$ predictors is taken at each split</li> <li>Only one of the chosen predictors is used during binary splitting</li> <li>Typically with $m\approx\sqrt{d}$</li> </ul> <p>The reason for such restriction on the allowed predictors used in the model is that when there is one strong predictor in the dataset, the majority of bagged trees will choose that predictors, leading to highly correlated tress. Averaging these correlated tress will not reduced the varaince much.</p> <ul> <li>Small value of m is usually helpful when there are large number of correlated predictors.</li> </ul> <h2 id="boosting">Boosting</h2> <p>The boosting envolves traning multiple small tress in seuqnce, with each fited with the residuals of previouse tree instead of $Y$. By fitting small trees to the residuals, the boosting process slowly imporve the output in areas where it does not perform well.</p> <ol> <li>Initilize the tree $\hat{f}(\mathbf{X})=0$ and residual $r_i=y_i$ for all i in the traning set</li> <li>Let $B$ be the total number of trees, repeat the following <ol> <li>Fit a new tree $\hat{f}_b$ with $\mathbf{X}$ and $\mathbf{r}$</li> <li>Update $\hat{f}(\mathbf{X})\leftarrow\hat{f}(\mathbf{X})+\lambda\hat{f}_b(\mathbf{X})$</li> <li>Update residuals $r_i\leftarrow r_i-\lambda \hat{f}_b(\mathbf{x}_i)$</li> </ol> </li> <li>Return the boosted model $\hat{f}(\mathbf{X})=\sum_{b=1}^B\lambda\hat{f}_b(\mathbf{X})$</li> </ol> <p>there are three tunable hyperparamters</p> <ul> <li>Number of trees $B$. This can be chose by cross-validation</li> <li>Learning rate $\lambda$. Chose depend on problem and number of trees</li> <li>Number of splits in each tree.</li> </ul> <p>The idea of boosting can also be applied to different machine learning methods, where the successive model learn the residule of the previouse one.</p> <h2 id="bayesian-additive-regression-trees">Bayesian Additive Regression Trees</h2>]]></content><author><name></name></author><category term="machine Learning"/><summary type="html"><![CDATA[Decision tree model in machine learning]]></summary></entry></feed>