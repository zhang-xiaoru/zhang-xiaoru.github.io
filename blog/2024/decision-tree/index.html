<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Decision Tree | Xiaoru Zhang </title> <meta name="author" content="Xiaoru Zhang"> <meta name="description" content="Decision tree model in machine learning"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zhang-xiaoru.github.io/blog/2024/decision-tree/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Xiaoru</span> Zhang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Decision Tree</h1> <p class="post-meta"> Created on November 11, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine Learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="regression-trees">Regression Trees</h1> <p>The regression trees use the condition on each node to split the predictor space into different region, representing by the leaves of the tree. The predicted mean of the response for a feacture point fall in the leave is given by the responbse average of traning observation within the region. In principle, the shape of the region can be airbutreary, but are typically troches as high-dimensional boxes.</p> <h2 id="formulasime">Formulasime</h2> <ul> <li> <p>Divide the $d$ dimensional predictor space repressenting by data vector $\mathbf{x}=(x_1, x_2, \cdots, x_d)$, into $J$ distinct non-ocerlaping regions $R_1, R_2, \cdots, R_J$.</p> </li> <li> <p>For every observation that falls into the region $R_j$, the prediction is same, which is the average of the response value for the traning objercation fall in $R_j$</p> </li> <li> <p>The goal is to find optimized regions ${R_i}$ that minimized the error \(\sum_{j=1}^{J}\sum_{\mathbf{x}_i\in R_j}(y_i-\hat{y}_{R_j}) \notag\) where $y_i$ is the reponse of train data point $\mathbf{x}<em>i$ amd $\hat{y}</em>{R_j}$ is the average of traning observation within $R_j$</p> </li> </ul> <h2 id="optimization">Optimization</h2> <p>Use recursive binary splitting, a top-down, greedy approach to find the minimized error.</p> <ol> <li> <table> <tbody> <tr> <td>For specific predictor $x_j$, splite the predictor space in to $R_1={\mathbf{x}</td> <td>x_j&lt;s_j}$ and $R_2={\mathbf{x}</td> <td>x_j\geq s_j}$, and find s that minimized the error.</td> </tr> </tbody> </table> </li> <li>Search thorugh all predictors and find the $(x_i, s_i)$ that has the smallest error.</li> <li>Repeat process 1, 2 for one of the splited region</li> <li>Repeat 3 until all region contains observations less than specific value</li> </ol> <h2 id="regularization">Regularization</h2> <p>If the tree we generate is too big, the tree would overfit the data. However, the naive approach simply stop the above process early will prohibite the tree to find a possible good split in deeper tree.</p> <p>A better strategy is to grow a very large tree and then prune it back in order to obtain a subtree.</p> <h3 id="cost-complexity-pruning-weakest-link-pruning">Cost complexity pruning (weakest link pruning)</h3> <p>Rather than consideirng every possible subtree, the cost complexity pruning use a hyperparameter $\alpha$ to add a punishment term for size of tree in the error function. For each value of $\alpha$ corresponds a subtree $T$ that minimized the error function \(\sum_{m=1}^{|T|}\sum_{\mathbf{x}_i\in{R_m}}(y_i-\hat{y}_{R_i})+\alpha|T|\notag\) where |T| represent the number of terminal nodes of the tree.</p> <h1 id="classification-trees">Classification Trees</h1> <p>The prdiction of an classification trees is same for each observation fall in the splited predictor space region, given by the most commonly occurring class of traning obsercations in the region.</p> <h1 id="ensemble-method-for-decistion-trees">Ensemble Method for Decistion Trees</h1> <p>An ensemble method is an approach that combines many simple weak learning to obtain a potentially very powerful model.</p> <h2 id="bagging">Bagging</h2> <p>The idea of bagging or Bootstrap aggregation is to take many traning sets from the population, and buid separte drecition modesl using for each traning set. The prediction is given by the avrageds of these model. By doing such, the variacne of the statistical learning model is reduced.</p> <p>In practice, instead of getting multiple traning set, people resample from the single training set, getting different bootstrapped traning data set. Suppose we enerate $B$ different traning sets from the original datastes, for each traning sets, we traning the model and get a regression relationship $\hat{f}_i(\mathbf{X})$, the final model would be the average of all the predictions \(f_{\text{beg}} = \frac{1}{B}\sum_{i=1}^{B}\hat{f}_i(\mathbf{X})\notag\)</p> <ul> <li>Bagging can be applied to many regression methods.</li> <li>Trees are growning using $B$ traning set, and are not pruned. Since the averaging process will reduces the variance.</li> </ul> <h2 id="random-forests">Random Forests</h2> <p>In random forest model, numbers of trees are duilded on bootstrapped traning smaples, and the overall prediction is given by the average. When building each decision trees, instead of splitting the predictor space searching through all predictors, a random sample of $m$ predictors is chosen.</p> <ul> <li>A fresh sample of $m$ predictors is taken at each split</li> <li>Only one of the chosen predictors is used during binary splitting</li> <li>Typically with $m\approx\sqrt{d}$</li> </ul> <p>The reason for such restriction on the allowed predictors used in the model is that when there is one strong predictor in the dataset, the majority of bagged trees will choose that predictors, leading to highly correlated tress. Averaging these correlated tress will not reduced the varaince much.</p> <ul> <li>Small value of m is usually helpful when there are large number of correlated predictors.</li> </ul> <h2 id="boosting">Boosting</h2> <p>The boosting envolves traning multiple small tress in seuqnce, with each fited with the residuals of previouse tree instead of $Y$. By fitting small trees to the residuals, the boosting process slowly imporve the output in areas where it does not perform well.</p> <ol> <li>Initilize the tree $\hat{f}(\mathbf{X})=0$ and residual $r_i=y_i$ for all i in the traning set</li> <li>Let $B$ be the total number of trees, repeat the following <ol> <li>Fit a new tree $\hat{f}_b$ with $\mathbf{X}$ and $\mathbf{r}$</li> <li>Update $\hat{f}(\mathbf{X})\leftarrow\hat{f}(\mathbf{X})+\lambda\hat{f}_b(\mathbf{X})$</li> <li>Update residuals $r_i\leftarrow r_i-\lambda \hat{f}_b(\mathbf{x}_i)$</li> </ol> </li> <li>Return the boosted model $\hat{f}(\mathbf{X})=\sum_{b=1}^B\lambda\hat{f}_b(\mathbf{X})$</li> </ol> <p>there are three tunable hyperparamters</p> <ul> <li>Number of trees $B$. This can be chose by cross-validation</li> <li>Learning rate $\lambda$. Chose depend on problem and number of trees</li> <li>Number of splits in each tree.</li> </ul> <p>The idea of boosting can also be applied to different machine learning methods, where the successive model learn the residule of the previouse one.</p> <h2 id="bayesian-additive-regression-trees">Bayesian Additive Regression Trees</h2> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/negtive-binom/">Negative Binomial Distribution</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/catalan-num/">Catalan Numbers</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/latex-2-word/">LaTex To Word Conversion</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Xiaoru Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>